{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, LabelBinarizer\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('AwA2-features\\Animals_with_Attributes2\\Features\\ResNet101\\AwA2-features.txt', header=None, sep=\" \", dtype = np.float64).values\n",
    "Y = pd.read_csv('AwA2-features\\Animals_with_Attributes2\\Features\\ResNet101\\AwA2-labels.txt', header=None).values\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "Y_bin = lb.fit_transform(Y)\n",
    "\n",
    "df = pd.DataFrame(columns=['method','accuracy','precision', 'recall', 'f1_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the format of X :[0.12702841 3.2361083  0.93514752 ... 0.67223716 0.03226495 0.4076162 ]\n",
      "the format of y: [1]\n",
      "the number of samples = 37322\n",
      "the number of samples X ?= Y: True\n",
      "the featurn dimension of X = 2048\n",
      "the number of class: 50\n",
      "the minimum class label:1\n"
     ]
    }
   ],
   "source": [
    "print(\"the format of X :\" + str(X[0]))\n",
    "print(\"the format of y: \" + str(Y[0]))\n",
    "print(\"the number of samples = \" + str(X.shape[0]))\n",
    "print(\"the number of samples X ?= Y: \" + str(X.shape[0] == Y.shape[0]))\n",
    "print(\"the featurn dimension of X = \" + str(X.shape[1]))\n",
    "print(\"the number of class: \"  + str(Y[:,0].max() - Y[:,0].min() + 1))\n",
    "print(\"the minimum class label:\" + str(Y[:,0].min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:(22393, 2048)\n",
      "Y_train:(22393, 1)\n",
      "Y_train_bin:(22393, 50)\n"
     ]
    }
   ],
   "source": [
    "#split the data to the 60% training set and 40% testing set, use array not dataframe\n",
    "#X_train, X_test, Y_train, Y_test, Y_train_bin, Y_test_bin = train_test_split(X[:2000, :], Y[:2000], Y_bin[:2000, :], test_size=0.4, random_state=66)\n",
    "X_train, X_test, Y_train, Y_test, Y_train_bin, Y_test_bin = train_test_split(X, Y, Y_bin, test_size=0.4, random_state=66)\n",
    "\n",
    "print(\"X_train:\" + str(X_train.shape))\n",
    "print(\"Y_train:\" + str(Y_train.shape))\n",
    "print(\"Y_train_bin:\" + str(Y_train_bin.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression accuracy: 0.9182798579945073\n",
      "Linear Regression precision: 0.9069363861159588\n",
      "Linear Regression recall: 0.8606600897290966\n",
      "Linear Regression f1_score: 0.8728671854912539\n"
     ]
    }
   ],
   "source": [
    "# linear regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#创建一个管道（Pipeline）实例\n",
    "LinearRegression_pipeline = make_pipeline(StandardScaler(), LinearRegression())\n",
    "LinearRegression_pipeline.fit(X_train, Y_train_bin)\n",
    "\n",
    "joblib.dump(LinearRegression, 'LinearRegression.pkl')\n",
    "\n",
    "predict_res = np.argmax(LinearRegression_pipeline.predict(X_test), axis = 1) + 1\n",
    "LinearRegression_accuracy = accuracy_score(Y_test, predict_res)\n",
    "LinearRegression_precision = precision_score(Y_test, predict_res, average='macro') #'micro', 'weighted'\n",
    "LinearRegression_recalll = recall_score(Y_test, predict_res, average='macro')\n",
    "LinearRegression_f1score = f1_score(Y_test, predict_res, average='macro')\n",
    "\n",
    "print(\"Linear Regression accuracy: \" + str(LinearRegression_accuracy))\n",
    "print(\"Linear Regression precision: \" + str(LinearRegression_precision))\n",
    "print(\"Linear Regression recall: \" + str(LinearRegression_recalll))\n",
    "print(\"Linear Regression f1_score: \" + str(LinearRegression_f1score))\n",
    "\n",
    "df = df.append(pd.DataFrame([['Linear Regression', LinearRegression_accuracy, LinearRegression_precision, LinearRegression_recalll, LinearRegression_f1score]], columns=df.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\IDE\\Anaconda\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\IDE\\Anaconda\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\IDE\\Anaconda\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l2_ovr Cross Validation accuracy: 0.922 +/- 0.003\n",
      "l2_mul Cross Validation accuracy: 0.925 +/- 0.002\n"
     ]
    }
   ],
   "source": [
    "# kfold and Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#choose the best penalty\n",
    "# create a Pipeline instance\n",
    "#LogisticRegression_pipeline_l1_ovr = make_pipeline(StandardScaler(), LogisticRegression(penalty='l1', multi_class='ovr', solver='lbfgs', max_iter=100))\n",
    "LogisticRegression_pipeline_l2_ovr = make_pipeline(StandardScaler(), LogisticRegression(penalty='l2', multi_class='ovr', solver='lbfgs', max_iter=1000))\n",
    "#LogisticRegression_pipeline_l1_mul = make_pipeline(StandardScaler(), LogisticRegression(penalty='l1', multi_class='multinomial', solver='lbfgs', max_iter=100))\n",
    "LogisticRegression_pipeline_l2_mul = make_pipeline(StandardScaler(), LogisticRegression(penalty='l2', multi_class='multinomial', solver='lbfgs', max_iter=1000))\n",
    "#pipeline = make_pipeline(LogisticRegression(multi_class='ovr'))\n",
    "#scores_l1_ovr = cross_val_score(LogisticRegression_pipeline_l1_ovr, X=X_train, y=Y_train.ravel(), cv=10)\n",
    "scores_l2_ovr = cross_val_score(LogisticRegression_pipeline_l2_ovr, X=X_train, y=Y_train.ravel(), cv=5)\n",
    "#scores_l1_mul = cross_val_score(LogisticRegression_pipeline_l1_mul, X=X_train, y=Y_train.ravel(), cv=10)\n",
    "scores_l2_mul = cross_val_score(LogisticRegression_pipeline_l2_mul, X=X_train, y=Y_train.ravel(), cv=5)\n",
    "\n",
    "#print('l1_ovr Cross Validation accuracy: %.3f +/- %.3f' % (np.mean(scores_l1_ovr),np.std(scores_l1_ovr)))\n",
    "print('l2_ovr Cross Validation accuracy: %.3f +/- %.3f' % (np.mean(scores_l2_ovr),np.std(scores_l2_ovr)))\n",
    "#print('l1 Cross Validation accuracy: %.3f +/- %.3f' % (np.mean(scores_l1_mul),np.std(scores_l1_mul)))\n",
    "print('l2_mul Cross Validation accuracy: %.3f +/- %.3f' % (np.mean(scores_l2_mul),np.std(scores_l2_mul)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LinearDiscriminantAnalysis_pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32me:\\class\\statics\\K-fold.ipynb Cell 7\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/class/statics/K-fold.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#choose the best logistic regression\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/class/statics/K-fold.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m LinearDiscriminantAnalysis_pipeline\u001b[39m.\u001b[39mfit(X_train, Y_train\u001b[39m.\u001b[39mravel())\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/class/statics/K-fold.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m predict_res \u001b[39m=\u001b[39m LinearDiscriminantAnalysis_pipeline\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/class/statics/K-fold.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m LinearDiscriminantAnalysis_accuracy \u001b[39m=\u001b[39m accuracy_score(Y_test, predict_res)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'LinearDiscriminantAnalysis_pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "#choose the best logistic regression don't run \n",
    "LogisticRegression_pipeline_l2_mul.fit(X_train, Y_train.ravel())\n",
    "\n",
    "predict_res = LogisticRegression_pipeline_l2_mul.predict(X_test)\n",
    "LogisticRegression_accuracy = accuracy_score(Y_test, predict_res)\n",
    "LogisticRegression_precision = precision_score(Y_test, predict_res, average='macro') #'micro', 'weighted'\n",
    "LogisticRegression_recalll = recall_score(Y_test, predict_res, average='macro')\n",
    "LogisticRegression_f1score = f1_score(Y_test, predict_res, average='macro')\n",
    "\n",
    "print(\"Linear Regression accuracy: \" + str(LogisticRegression_accuracy))\n",
    "print(\"Linear Regression precision: \" + str(LogisticRegression_precision))\n",
    "print(\"Linear Regression recall: \" + str(LogisticRegression_recalll))\n",
    "print(\"Linear Regression f1_score: \" + str(LogisticRegression_f1score))\n",
    "\n",
    "df = df.append(pd.DataFrame([['Linear Regression', LinearRegression_accuracy, LinearRegression_precision, LinearRegression_recalll, LinearRegression_f1score]], columns=df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Discriminant accuracy: 0.9188157277781499\n",
      "Linear Discriminant precision: 0.9013561344691954\n",
      "Linear Discriminant recall: 0.8876857061359066\n",
      "Linear Discriminant f1_score: 0.8920958319561848\n"
     ]
    }
   ],
   "source": [
    "#linear discriminant analysis\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "LinearDiscriminantAnalysis_pipeline = make_pipeline(StandardScaler(), LinearDiscriminantAnalysis(solver='svd'))\n",
    "LinearDiscriminantAnalysis_pipeline.fit(X_train, Y_train.ravel())\n",
    "\n",
    "joblib.dump(LinearDiscriminantAnalysis_pipeline, 'LinearDiscriminantAnalysis.pkl')\n",
    "\n",
    "predict_res = LinearDiscriminantAnalysis_pipeline.predict(X_test)\n",
    "LinearDiscriminantAnalysis_accuracy = accuracy_score(Y_test, predict_res)\n",
    "LinearDiscriminantAnalysis_precision = precision_score(Y_test, predict_res, average='macro') #'micro', 'weighted'\n",
    "LinearDiscriminantAnalysis_recalll = recall_score(Y_test, predict_res, average='macro')\n",
    "LinearDiscriminantAnalysis_f1score = f1_score(Y_test, predict_res, average='macro')\n",
    "\n",
    "print(\"Linear Discriminant accuracy: \" + str(LinearDiscriminantAnalysis_accuracy))\n",
    "print(\"Linear Discriminant precision: \" + str(LinearDiscriminantAnalysis_precision))\n",
    "print(\"Linear Discriminant recall: \" + str(LinearDiscriminantAnalysis_recalll))\n",
    "print(\"Linear Discriminant f1_score: \" + str(LinearDiscriminantAnalysis_f1score))\n",
    "\n",
    "df = df.append(pd.DataFrame([['Linear Discriminant Analysis', LinearDiscriminantAnalysis_accuracy, LinearDiscriminantAnalysis_precision, LinearDiscriminantAnalysis_recalll, LinearDiscriminantAnalysis_f1score]], columns=df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\IDE\\Anaconda\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "d:\\IDE\\Anaconda\\anaconda\\envs\\tensorflow\\lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# kfold and SVM\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svm_pipeline_ovr = make_pipeline(StandardScaler(), LinearSVC(penalty='l2', multi_class='ovr', dual='auto', max_iter=1000))\n",
    "svm_pipeline_cram = make_pipeline(StandardScaler(), LinearSVC(penalty='l2', multi_class='crammer_singer', dual='auto', max_iter=1000))\n",
    "\n",
    "scores_l2_ovr = cross_val_score(svm_pipeline_ovr, X=X_train, y=Y_train.ravel(), cv=5)\n",
    "scores_l2_mul = cross_val_score(svm_pipeline_cram, X=X_train, y=Y_train.ravel(), cv=5)\n",
    "\n",
    "print('l2_ovr Cross Validation accuracy: %.3f +/- %.3f' % (np.mean(scores_l2_ovr),np.std(scores_l2_ovr)))\n",
    "print('l2_mul Cross Validation accuracy: %.3f +/- %.3f' % (np.mean(scores_l2_mul),np.std(scores_l2_mul)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the best svm\n",
    "LinearDiscriminantAnalysis_pipeline.fit(X_train, Y_train.ravel())\n",
    "\n",
    "predict_res = LinearDiscriminantAnalysis_pipeline.predict(X_test)\n",
    "LinearDiscriminantAnalysis_accuracy = accuracy_score(Y_test, predict_res)\n",
    "LinearDiscriminantAnalysis_precision = precision_score(Y_test, predict_res, average='macro') #'micro', 'weighted'\n",
    "LinearDiscriminantAnalysis_recalll = recall_score(Y_test, predict_res, average='macro')\n",
    "LinearDiscriminantAnalysis_f1score = f1_score(Y_test, predict_res, average='macro')\n",
    "\n",
    "print(\"Linear Regression accuracy: \" + str(LinearDiscriminantAnalysis_accuracy))\n",
    "print(\"Linear Regression precision: \" + str(LinearDiscriminantAnalysis_precision))\n",
    "print(\"Linear Regression recall: \" + str(LinearDiscriminantAnalysis_recalll))\n",
    "print(\"Linear Regression f1_score: \" + str(LinearDiscriminantAnalysis_f1score))\n",
    "\n",
    "df = df.append(pd.DataFrame([['Linear Regression', LinearRegression_accuracy, LinearRegression_precision, LinearRegression_recalll, LinearRegression_f1score]], columns=df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              method  accuracy  precision    recall  f1_score\n",
      "0  Linear Regression    0.9775   0.967475  0.967692  0.967229\n"
     ]
    }
   ],
   "source": [
    "print(df)\n",
    "df.to_excel('res.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
